{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN76T0hLjNJs4BH+hkVtJ4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuruwu/NeuralNetwork/blob/main/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Si5nh2cMs4gG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Dataset of Diabetes .csv')"
      ],
      "metadata": {
        "id": "RvrIbzmmtqbO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trim the Customer ID and Patient no from the table and seperate out the result into another table\n",
        "X = pd.DataFrame(dataset.iloc[:, 2:13].values)\n",
        "Y = dataset.iloc[:, 13].values\n",
        "print(Y)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOzS856ttq1-",
        "outputId": "5f9f8c3c-b2dc-4c45-a462-86a680456be0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'P' 'P' 'P' 'P' 'P'\n",
            " 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P'\n",
            " 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P'\n",
            " 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'P' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n",
            "    0   1     2   3     4    5    6    7    8     9     10\n",
            "0    F  50   4.7  46   4.9  4.2  0.9  2.4  1.4   0.5  24.0\n",
            "1    M  26   4.5  62   4.9  3.7  1.4  1.1  2.1   0.6  23.0\n",
            "2    F  50   4.7  46   4.9  4.2  0.9  2.4  1.4   0.5  24.0\n",
            "3    F  50   4.7  46   4.9  4.2  0.9  2.4  1.4   0.5  24.0\n",
            "4    M  33   7.1  46   4.9  4.9  1.0  0.8  2.0   0.4  21.0\n",
            "..  ..  ..   ...  ..   ...  ...  ...  ...  ...   ...   ...\n",
            "995  M  71  11.0  97   7.0  7.5  1.7  1.2  1.8   0.6  30.0\n",
            "996  M  31   3.0  60  12.3  4.1  2.2  0.7  2.4  15.4  37.2\n",
            "997  M  30   7.1  81   6.7  4.1  1.1  1.2  2.4   8.1  27.4\n",
            "998  M  38   5.8  59   6.7  5.3  2.0  1.6  2.9  14.0  40.5\n",
            "999  M  54   5.0  67   6.9  3.8  1.7  1.1  3.0   0.7  33.0\n",
            "\n",
            "[1000 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Y = np.char.strip(Y)\n",
        "#print(Y)"
      ],
      "metadata": {
        "id": "OaKXrToX42E0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X_0 = LabelEncoder()\n",
        "X.loc[:, 0] = labelencoder_X_0.fit_transform(X.iloc[:, 0]) #Turning male and female into binary representation (0 or 1)\n",
        "print(X)"
      ],
      "metadata": {
        "id": "pqtND7pMt0rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ee73cd-ea57-4aa6-82da-33706f4ef221"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0   1     2   3     4    5    6    7    8     9     10\n",
            "0    0  50   4.7  46   4.9  4.2  0.9  2.4  1.4   0.5  24.0\n",
            "1    1  26   4.5  62   4.9  3.7  1.4  1.1  2.1   0.6  23.0\n",
            "2    0  50   4.7  46   4.9  4.2  0.9  2.4  1.4   0.5  24.0\n",
            "3    0  50   4.7  46   4.9  4.2  0.9  2.4  1.4   0.5  24.0\n",
            "4    1  33   7.1  46   4.9  4.9  1.0  0.8  2.0   0.4  21.0\n",
            "..  ..  ..   ...  ..   ...  ...  ...  ...  ...   ...   ...\n",
            "995  1  71  11.0  97   7.0  7.5  1.7  1.2  1.8   0.6  30.0\n",
            "996  1  31   3.0  60  12.3  4.1  2.2  0.7  2.4  15.4  37.2\n",
            "997  1  30   7.1  81   6.7  4.1  1.1  1.2  2.4   8.1  27.4\n",
            "998  1  38   5.8  59   6.7  5.3  2.0  1.6  2.9  14.0  40.5\n",
            "999  1  54   5.0  67   6.9  3.8  1.7  1.1  3.0   0.7  33.0\n",
            "\n",
            "[1000 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehotencoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
        "Y = onehotencoder.fit_transform(Y.reshape(-1, 1))\n",
        "print(Y) #Formatting The Classes N P Y into a binary matrix\n",
        "classes_order = onehotencoder.categories_[0]\n",
        "print(classes_order)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw2SpXNY0ysl",
        "outputId": "b19eb64f-3513-40bd-9832-1ce712f9b556"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n",
            "['N' 'P' 'Y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) #20% of dataset will be used for testing."
      ],
      "metadata": {
        "id": "5ugIrN_9ufw7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test) #Normalize the data\n",
        "print(X_test)\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzhejhQ4uW3X",
        "outputId": "082b6b51-cf0e-4f29-82df-be83742df9f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.86634118 -2.82406172 -0.55374694 ... -0.00926875 -0.29117027\n",
            "   1.4760338 ]\n",
            " [ 0.86634118 -0.25508285  0.10876351 ... -0.54208306 -0.45133727\n",
            "   0.09798425]\n",
            " [ 0.86634118  0.30339082 -0.65312351 ...  0.70115033 -0.21108677\n",
            "   0.49171269]\n",
            " ...\n",
            " [-1.15427965 -2.26558805  0.17501456 ...  1.14516226 -0.10430876\n",
            "  -1.28006531]\n",
            " [ 0.86634118 -0.25508285 -0.4874959  ... -0.80849021 -0.10430876\n",
            "   1.08230536]\n",
            " [ 0.86634118 -1.14864072 -0.25561724 ... -0.63088544 -0.29117027\n",
            "  -0.09887998]]\n",
            "[[ 0.86634118  0.97355922 -0.0568641  ... -0.09807113 -0.26447577\n",
            "   0.09798425]\n",
            " [ 0.86634118 -0.14338811  0.07563799 ... -0.09807113 -0.26447577\n",
            "  -0.2957442 ]\n",
            " [-1.15427965  0.86186449 -0.61999799 ... -1.51890929 -0.10430876\n",
            "   1.27916958]\n",
            " ...\n",
            " [ 0.86634118  0.41508555 -0.35499381 ... -0.09807113 -0.26447577\n",
            "   0.09798425]\n",
            " [ 0.86634118  0.19169609 -0.85187665 ...  0.8787551  -0.07761426\n",
            "   1.27916958]\n",
            " [ 0.86634118  0.75016976 -0.32186828 ... -1.07489737 -0.21108677\n",
            "   0.88544114]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#The term \"dense\" implies that each neuron in this layer is connected to every neuron in the previous layer, forming a fully connected layer."
      ],
      "metadata": {
        "id": "vHufgC1Xukxs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential() #Creating our model"
      ],
      "metadata": {
        "id": "ZPchaP42wWhk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input and Hidden Layer\n",
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11))\n",
        "#Add 6 neurons to our layer that takes 11 inputs (Each column). RELU activation."
      ],
      "metadata": {
        "id": "gwuFQDPzwcqi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu')) #Hidden Layer 2"
      ],
      "metadata": {
        "id": "XO8JRmFJH7xq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=3, kernel_initializer='uniform', activation='softmax')) #Output Layer (3 Outputs for 3 Possible Values N P Y)"
      ],
      "metadata": {
        "id": "IQCGGR2VyZ93"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "0-qh85oMykEU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=classifier.fit(X_train, Y_train, batch_size = 10, epochs = 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kv3Xw1oylxi",
        "outputId": "b22bda3a-e7d5-40fc-8f2b-e0a62241a84d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "80/80 [==============================] - 7s 5ms/step - loss: 1.0342 - accuracy: 0.8325\n",
            "Epoch 2/80\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7085 - accuracy: 0.8350\n",
            "Epoch 3/80\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4103 - accuracy: 0.8350\n",
            "Epoch 4/80\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3458 - accuracy: 0.8350\n",
            "Epoch 5/80\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.3245 - accuracy: 0.8350\n",
            "Epoch 6/80\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3106 - accuracy: 0.8350\n",
            "Epoch 7/80\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.2999 - accuracy: 0.8350\n",
            "Epoch 8/80\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.2908 - accuracy: 0.8350\n",
            "Epoch 9/80\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.8350\n",
            "Epoch 10/80\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.8350\n",
            "Epoch 11/80\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.2698 - accuracy: 0.8350\n",
            "Epoch 12/80\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.2642 - accuracy: 0.8350\n",
            "Epoch 13/80\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.2589 - accuracy: 0.8413\n",
            "Epoch 14/80\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.2546 - accuracy: 0.8938\n",
            "Epoch 15/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9050\n",
            "Epoch 16/80\n",
            "80/80 [==============================] - 1s 6ms/step - loss: 0.2477 - accuracy: 0.9062\n",
            "Epoch 17/80\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.2453 - accuracy: 0.9062\n",
            "Epoch 18/80\n",
            "80/80 [==============================] - 1s 6ms/step - loss: 0.2422 - accuracy: 0.9087\n",
            "Epoch 19/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9112\n",
            "Epoch 20/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9125\n",
            "Epoch 21/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.9150\n",
            "Epoch 22/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.9137\n",
            "Epoch 23/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9125\n",
            "Epoch 24/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9112\n",
            "Epoch 25/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9175\n",
            "Epoch 26/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9137\n",
            "Epoch 27/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9087\n",
            "Epoch 28/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9137\n",
            "Epoch 29/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9112\n",
            "Epoch 30/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9100\n",
            "Epoch 31/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9112\n",
            "Epoch 32/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9050\n",
            "Epoch 33/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9112\n",
            "Epoch 34/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9100\n",
            "Epoch 35/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9112\n",
            "Epoch 36/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9125\n",
            "Epoch 37/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9150\n",
            "Epoch 38/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9137\n",
            "Epoch 39/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9137\n",
            "Epoch 40/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9137\n",
            "Epoch 41/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9137\n",
            "Epoch 42/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9150\n",
            "Epoch 43/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9150\n",
            "Epoch 44/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9162\n",
            "Epoch 45/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9150\n",
            "Epoch 46/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9150\n",
            "Epoch 47/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9162\n",
            "Epoch 48/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1858 - accuracy: 0.9175\n",
            "Epoch 49/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9162\n",
            "Epoch 50/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9150\n",
            "Epoch 51/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9162\n",
            "Epoch 52/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.9150\n",
            "Epoch 53/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9150\n",
            "Epoch 54/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9162\n",
            "Epoch 55/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9175\n",
            "Epoch 56/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9162\n",
            "Epoch 57/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9187\n",
            "Epoch 58/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9175\n",
            "Epoch 59/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9187\n",
            "Epoch 60/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9237\n",
            "Epoch 61/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9287\n",
            "Epoch 62/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9212\n",
            "Epoch 63/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9262\n",
            "Epoch 64/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9287\n",
            "Epoch 65/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9262\n",
            "Epoch 66/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9287\n",
            "Epoch 67/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9300\n",
            "Epoch 68/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9287\n",
            "Epoch 69/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9225\n",
            "Epoch 70/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1524 - accuracy: 0.9312\n",
            "Epoch 71/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9300\n",
            "Epoch 72/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9300\n",
            "Epoch 73/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9312\n",
            "Epoch 74/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9312\n",
            "Epoch 75/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9325\n",
            "Epoch 76/80\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9250\n",
            "Epoch 77/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9300\n",
            "Epoch 78/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9287\n",
            "Epoch 79/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9325\n",
            "Epoch 80/80\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "IojnI6lV-Fyd",
        "outputId": "848cdeae-8183-47ec-f679-c795ef9e1244"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = classifier.evaluate(X_test, Y_test) #Using test data\n",
        "\n",
        "#Print the loss and accuracy (metrics)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "oB9O9Ok6Mc41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a335b9-6582-4d19-f93f-48852ed712f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9500\n",
            "Test Loss: 0.13392429053783417\n",
            "Test Accuracy: 0.949999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get predictions on the test data\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(Y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maqvTPVkF7iz",
        "outputId": "51fec3f2-3f86-419e-ac29-44441afb9463"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "Confusion Matrix:\n",
            "[[ 16   0   0]\n",
            " [  0   3   5]\n",
            " [  5   0 171]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the probabilities of each class between 0 and 1 using scientific notation.\n",
        "y_probabilities = classifier.predict(X_test)\n",
        "#Round to two decimal places for readability.\n",
        "y_probabilities = np.round(y_probabilities, decimals=2)\n",
        "print(y_probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCFubXrox0Q",
        "outputId": "2ee0e466-d685-4cdd-a639-7f01c98c7318"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n",
            "[[0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.04 0.96]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.02 0.98]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.22 0.78]\n",
            " [0.73 0.18 0.09]\n",
            " [0.77 0.15 0.07]\n",
            " [0.77 0.15 0.07]\n",
            " [0.61 0.25 0.14]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.16 0.45 0.39]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.04 0.96]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.14 0.46 0.41]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.03 0.97]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.05 0.45 0.5 ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.05 0.95]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.29 0.71]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.02 0.98]\n",
            " [0.76 0.16 0.08]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.12 0.88]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.06 0.45 0.49]\n",
            " [0.   0.   1.  ]\n",
            " [0.71 0.19 0.1 ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.43 0.34 0.22]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.01 0.99]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.76 0.16 0.08]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.05 0.95]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.01 0.38 0.61]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.14 0.46 0.41]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.   1.  ]\n",
            " [0.77 0.15 0.07]\n",
            " [0.   0.   1.  ]\n",
            " [0.   0.15 0.85]]\n"
          ]
        }
      ]
    }
  ]
}